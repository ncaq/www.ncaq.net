---
title: Linuxでは何故SSD向けのキャッシュ機構をZFSのようにファイルシステムに依存せずにbcacheのような形で提供しているのか考察
---

> 選択2: SSD向けのキャッシュ機構
>
> SSD向けのキャッシュ機構bcache Linuxカーネル3.10ではSSD向けのキャッシュ機構bcacheが新たにサポートされた。
> ファイルシステムZFSなどではSSDをキャッシュとして使うメカニズムを持っているが、bcacheはファイルシステムなどに依存しない独立した形で提供されている。
> Linuxのアプローチではファイルシステムにも依存しないアプローチを採用するのは何故か論じなさい。

ZFSのメインターゲットであるSolarisにも[DCD -- Disk Caching Disk](http://www.ele.uri.edu/research/hpcl/DCD/DCD.html)というbcacheに似たようなソフトウェアが存在するようです.
しかし,殆ど実用されていないようなので例外として無視します.

# Linuxのファイルシステムは多彩である

Linuxのファイルシステムは多彩です.

Linuxカーネル4.12.12で`make menuconfig`して確かめてみると,
**Miscellaneous**ではないメジャーなファイルシステムだけでも,

* ext3
* ext4
* Reiserfs
* JFS
* XFS
* GFS2
* Btrfs
* NILFS2
* F2FS

といった多種多様なファイルシステムがサポートされていることがわかります.

実際のディストリビューションのデフォルトのファイルシステムも,

* Debian: ext4
* RHEL: XFS
* Fedora: Btrfs
* OpenSUSE: Btrfs
* Gentoo, Arch: デフォルトを定めていない

などと分かれています.

ちなみに真偽は不明ですが
[List of default file systems - Wikipedia](https://en.wikipedia.org/wiki/List_of_default_file_systems)
というページがあって面白かったです.

また,LinuxのファイルシステムにはBtrfsというCoWやスナップショット機能を備えた既に高機能なファイルシステムが存在しているのも特筆すべきポイントです.

対してZFSはSolaris向けに開発されましたが,SolarisのファイルシステムはZFS以前はUFS(Unix File System)で統一されていました.

[[ThinkIT] 第2回：ファイルシステムを比較してみる (1/3)](https://thinkit.co.jp/free/solaris10/4/2/1.html)

そして,ZFSは次世代ファイルシステムとして扱われています.

つまり,ZFSがサポートするOSであるSolarisでは,ファイルシステムに依存しない仕組みで提供しても,ZFSに機能を追加しても,SSDキャッシュを求めるようなパワーユーザをサポートできる割合はほぼ同じということになります.

LinuxではファイルシステムにSSDキャッシュ機能を積んでも,一部のユーザしかサポートすることが出来ません.

LinuxコミュニティがもしSSDキャッシュ機能をファイルシステムに搭載するなら,高機能で現在も活発に開発が進められているBtrfsに追加するでしょう.
しかし,XFSも多くのエンタープライズ向け分野に使われています.

# ファイルシステムの安定性

これは先程の項で各OSのデフォルトファイルシステムを調べていてわかったことですが,Linuxカーネルはファイルシステムの互換性を大事にしているということがわかりました.

Solarisや*BSDは主にUFS(Unix File System)というファイルシステムを使っていますが,各OSはファイルシステムに対して独自の拡張を行っていて,UFSをサポートしていてもOSごとの互換性がありません.

BSDでは互換性を破壊するような変更をファイルシステムに加えても,ファイルシステムの名前はUFSのままになっています.

Linuxではそのようなことはありません,extなどのファイルシステムは機能変更ごとに名前を変えてきました.

Linuxではファイルシステムに対する機能追加は慎重に行われているのではないでしょうか.

# device-mapperの存在

そもそもLinuxのSSDキャッシュには

* bcache
* dm-cache
* dm-writeboost([死んだ。作者が飽きたから](http://akiradeveloper.hatenadiary.com/entry/2017/05/31/232526))
* EnhanceIO(最新のカーネルで使えないため死)

などの複数の機構が存在しますが,これらは全てdevice-mapperというフレームワークで構築されています.

* [device-mapper 解説](http://lc.linux.or.jp/lc2009/slide/T-02-slide.pdf)
* [SSDキャッシュの歴史 - テストステ論](http://akiradeveloper.hatenadiary.com/entry/2016/09/23/213454)
* [device-mapperの仕組み (1) device-mapperの概要 - テストステ論](http://akiradeveloper.hatenadiary.com/entry/2013/05/11/220634)

参考スライドから引用すると,ディスクIOは

1. アプリケーション
2. ファイルシステム
3. ブロックデバイスドライバ(共通部分)
4. ブロックデバイスドライバ(ハードウェア固有部分)
5. ストレージデバイス

の順に行われます.

Linuxではdevice-mapperがブロックデバイスドライバ(共通部分)を抽象化しています.

SolarisにはVFSはありましたが,device-mapperのような仕組みはありません.
OpenSolarisで作ろうとしている試みは存在するようですが…
[imp/devmapper: Solaris device mapper](https://github.com/imp/devmapper)

なので,SSDによるキャッシュ機能を追加しようとすると,抽象化されている最も下位のレベルはファイルシステムなので,そこに追加する必要があります.

しかし,Linuxではdevice-mapperによってブロックデバイスドライバがある程度抽象化されているので,ブロックデバイスレベルでキャッシュ機能などを実現することが出来ます.

これが,ZFS(Solaris)ではファイルシステムにSSDキャッシュ機能が追加されて,Linuxではブロックデバイスレベルでファイルシステムに依存しないSSDキャッシュ機能がマージされた最も大きな理由です.
